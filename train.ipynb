{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipaddress\n",
    "from datetime import datetime\n",
    "import time\n",
    "import keras\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer as DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 10780784: expected 10 fields, saw 11\\nSkipping line 10793876: expected 10 fields, saw 11\\n'\n",
      "b'Skipping line 10821923: expected 10 fields, saw 11\\n'\n",
      "C:\\Users\\ASUS\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data_full.csv\", sep = \";\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(\"./catalog.csv\", sep = \";\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ip</th>\n",
       "      <th>track_id</th>\n",
       "      <th>cookie</th>\n",
       "      <th>live</th>\n",
       "      <th>user_id</th>\n",
       "      <th>referer</th>\n",
       "      <th>uagent</th>\n",
       "      <th>rightholder</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1517778000</td>\n",
       "      <td>230.59.74.120</td>\n",
       "      <td>10912114</td>\n",
       "      <td>42536dc7a8578b0cfac05f704977429a</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https%3A%2F%2Frutube.ru%2Fvideo%2F0f5c9c5839b1...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64) Apple...</td>\n",
       "      <td>2</td>\n",
       "      <td>1480930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1517778000</td>\n",
       "      <td>218.222.225.36</td>\n",
       "      <td>10885813</td>\n",
       "      <td>8f92f3f2b1e7a2498761b8cb3b1d03c3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https%3A%2F%2Frutube.ru%2Fvideo%2Fd8068436dcf5...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>301323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1517778000</td>\n",
       "      <td>55.63.241.224</td>\n",
       "      <td>6948236</td>\n",
       "      <td>336d5ebc5436534e61d16e63ddfca327</td>\n",
       "      <td>-</td>\n",
       "      <td>2.231332e+09</td>\n",
       "      <td>http%3A%2F%2Fandroid.rutube.ru%2F</td>\n",
       "      <td>okhttp/2.6.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1517778000</td>\n",
       "      <td>230.34.98.99</td>\n",
       "      <td>8481402</td>\n",
       "      <td>cf8dd809edf104873a1c57921b34f25e</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https%3A%2F%2Frutube.ru%2Fvideo%2F1058cf249e46...</td>\n",
       "      <td>Mozilla/5.0 (Linux; Android 7.1.2; Redmi 4X Bu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>721346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1517778000</td>\n",
       "      <td>232.3.41.226</td>\n",
       "      <td>10908060</td>\n",
       "      <td>4ca525a1d60de6d74e3c32529fe47ab5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https%3A%2F%2Fyastatic.net%2Fvideo-player%2F0x...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>135</td>\n",
       "      <td>599848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp              ip  track_id                            cookie  \\\n",
       "0  1517778000   230.59.74.120  10912114  42536dc7a8578b0cfac05f704977429a   \n",
       "1  1517778000  218.222.225.36  10885813  8f92f3f2b1e7a2498761b8cb3b1d03c3   \n",
       "2  1517778000   55.63.241.224   6948236  336d5ebc5436534e61d16e63ddfca327   \n",
       "3  1517778000    230.34.98.99   8481402  cf8dd809edf104873a1c57921b34f25e   \n",
       "4  1517778000    232.3.41.226  10908060  4ca525a1d60de6d74e3c32529fe47ab5   \n",
       "\n",
       "  live       user_id                                            referer  \\\n",
       "0    0           NaN  https%3A%2F%2Frutube.ru%2Fvideo%2F0f5c9c5839b1...   \n",
       "1    0           NaN  https%3A%2F%2Frutube.ru%2Fvideo%2Fd8068436dcf5...   \n",
       "2    -  2.231332e+09                  http%3A%2F%2Fandroid.rutube.ru%2F   \n",
       "3    0           NaN  https%3A%2F%2Frutube.ru%2Fvideo%2F1058cf249e46...   \n",
       "4    0           NaN  https%3A%2F%2Fyastatic.net%2Fvideo-player%2F0x...   \n",
       "\n",
       "                                              uagent rightholder author_id  \n",
       "0  Mozilla/5.0 (Windows NT 6.1; Win64; x64) Apple...           2   1480930  \n",
       "1  Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.3...           2    301323  \n",
       "2                                       okhttp/2.6.0           -         -  \n",
       "3  Mozilla/5.0 (Linux; Android 7.1.2; Redmi 4X Bu...         NaN    721346  \n",
       "4  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...         135    599848  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idec</th>\n",
       "      <th>track_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>title</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>episode_global</th>\n",
       "      <th>date_efir</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR592505</td>\n",
       "      <td>10258734</td>\n",
       "      <td>cd59084eb50e6ebe9fe20ad04e0c17db</td>\n",
       "      <td>1.045685e+10</td>\n",
       "      <td>\\tБыть или не быть, 1 сезон, 1 серия</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>02.04.2017 22:00:34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR609630</td>\n",
       "      <td>10843255</td>\n",
       "      <td>a5d2e6bae4752d9ec0fae9b53f00700d</td>\n",
       "      <td>1.059247e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR597128</td>\n",
       "      <td>10573153</td>\n",
       "      <td>bcd45606c1f7cbb5cb9d1dbd7d346cc3</td>\n",
       "      <td>1.047956e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>06.09.2017 22:46:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR257331</td>\n",
       "      <td>6617650</td>\n",
       "      <td>609217ac7b8c4e55d44c4a29bf52554b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Интерны. История болезни\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.06.2012 22:00:44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR529698</td>\n",
       "      <td>7991493</td>\n",
       "      <td>bde3620ba038b3e8dd41d03bf516a7eb</td>\n",
       "      <td>1.024102e+10</td>\n",
       "      <td>#ЖАННАПОЖЕНИ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>05.09.2015 13:30:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idec  track_id                          video_id     series_id  \\\n",
       "0  PR592505  10258734  cd59084eb50e6ebe9fe20ad04e0c17db  1.045685e+10   \n",
       "1  PR609630  10843255  a5d2e6bae4752d9ec0fae9b53f00700d  1.059247e+10   \n",
       "2  PR597128  10573153  bcd45606c1f7cbb5cb9d1dbd7d346cc3  1.047956e+10   \n",
       "3  PR257331   6617650  609217ac7b8c4e55d44c4a29bf52554b           NaN   \n",
       "4  PR529698   7991493  bde3620ba038b3e8dd41d03bf516a7eb  1.024102e+10   \n",
       "\n",
       "                                  title  season  episode  episode_global  \\\n",
       "0  \\tБыть или не быть, 1 сезон, 1 серия     1.0      1.0             1.0   \n",
       "1                                   NaN    11.0      1.0             1.0   \n",
       "2                                   NaN     7.0      1.0             1.0   \n",
       "3            \"Интерны. История болезни\"     NaN      NaN             NaN   \n",
       "4                          #ЖАННАПОЖЕНИ     1.0      1.0           101.0   \n",
       "\n",
       "             date_efir  duration  \n",
       "0  02.04.2017 22:00:34       NaN  \n",
       "1                  NaN       NaN  \n",
       "2  06.09.2017 22:46:05       NaN  \n",
       "3  12.06.2012 22:00:44       NaN  \n",
       "4  05.09.2015 13:30:00       NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_device(df):\n",
    "    regexpDesktop = re.compile('(Windows|Linux|Mozilla)')\n",
    "    regexpMobile = re.compile('(iPhone|RutubeAndroid|okhttp|CFNetwork|UCBrowser)')\n",
    "    regexpTablet = re.compile('(iPad)')\n",
    "    \n",
    "    df['device'] = pd.Series('0', index=df.index)\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            if regexpDesktop.search(df['uagent'].iloc[i]):\n",
    "                df['device'][i] = 'desktop'\n",
    "            elif regexpMobile.search(df['uagent'].iloc[i]):\n",
    "                df['device'][i] = 'mobile'\n",
    "            elif regexpTablet.search(df['uagent'].iloc[i]):\n",
    "                df['device'][i] = 'mobile'\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeData(data1, data2, field):\n",
    "    data1[field] = pd.to_numeric(data1[field], errors = 'coerce')\n",
    "    data2[field] = pd.to_numeric(data2[field], errors = 'coerce')\n",
    "    return pd.merge(data1, data2, left_on=field, right_on=field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convIpToNumber(data):\n",
    "    return data.apply(lambda x: int(ipaddress.IPv4Address(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyDate(x):\n",
    "    try:\n",
    "        data = time.strptime(x, \"%d.%m.%Y %H:%M:%S\")\n",
    "        return int(time.mktime(data))\n",
    "    except:\n",
    "        return 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confDateStringToTimestamp(data):\n",
    "    return data.apply(lambda x: applyDate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_users_with_n_views(data, user_column = \"ip\", seq_len = 4):\n",
    "    by_user = data.groupby(user_column)\n",
    "    by_user = by_user.filter(lambda x: len(x) >= seq_len)\n",
    "    return by_user\n",
    "\n",
    "def extract_sequences_by_user(data, user_column = \"ip\"):\n",
    "    return data.groupby(user_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_videos_with_n_views(data, n = 1000):\n",
    "    data[\"track_id\"] = pd.to_numeric(data[\"track_id\"], errors = 'coerce', downcast = 'integer')\n",
    "    data = data[data[\"track_id\"].notnull()]\n",
    "    data_top_n = data.groupby(\"track_id\").filter(lambda x: len(x) >= n)\n",
    "    return data_top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['ip'] = convIpToNumber(data['ip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_top_n = filter_videos_with_n_views(data)\n",
    "# print(len(data_top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepared = filter_users_with_n_views(data_top_n)\n",
    "# print(len(prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [ 'series_id', 'device', 'idec', 'author_id']\n",
    "\n",
    "def label_encoder(data):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data)\n",
    "    return le\n",
    "\n",
    "def create_cat_vectorizer(data):\n",
    "    \n",
    "    cat = data.drop( numeric_cols, axis = 1 )\n",
    "    cat.fillna( 'NA', inplace = True )\n",
    "    x_cat = cat.to_dict( orient = 'records' )\n",
    "    \n",
    "    vectorizer = DV( sparse = False )\n",
    "    vectorizer.fit(x_cat)\n",
    "    \n",
    "    return vectorizer\n",
    "\n",
    "def cat_vectorize(data, vectorizer):\n",
    "    \n",
    "    cat = data.drop( numeric_cols, axis = 1 )\n",
    "    cat.fillna( 'NA', inplace = True )\n",
    "    x_cat = cat.to_dict( orient = 'records' )\n",
    "    \n",
    "    return vectorizer.transform(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_null_value(x):\n",
    "    if (x == 'null'):\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def data_scale(data):\n",
    "    scaler = StandardScaler()\n",
    "    data.fillna(0, inplace = True )\n",
    "    data = data.apply(lambda x: replace_null_value(x))\n",
    "    print(data)\n",
    "    data = scaler.fit_transform(data.reshape(-1, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_num_and_cat(data):\n",
    "    data['date_efir'] = data_scale(data['date_efir'])\n",
    "    data['duration'] = data_scale(data['duration'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, catalog):\n",
    "    \n",
    "    data['ip'] = convIpToNumber(data['ip'])\n",
    "    \n",
    "    data = filter_videos_with_n_views(data)\n",
    "    print(len(data_top_n))\n",
    "    \n",
    "    data = filter_users_with_n_views(data)\n",
    "    print(len(data))\n",
    "    \n",
    "    data = mergeData(data, catalog, \"track_id\")\n",
    "    \n",
    "    data['date_efir'] = confDateStringToTimestamp(data['date_efir'])\n",
    "    \n",
    "    data = data_to_num_and_cat(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "prepared = prepare_data(data, catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['series_id' 'device' 'idec'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-48cbdc540494>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcat_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_cat_vectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_vectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_vectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-4aa3f7e817b7>\u001b[0m in \u001b[0;36mcreate_cat_vectorizer\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_cat_vectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnumeric_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;34m'series_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'device'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'idec'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'author_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mx_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mnumeric_cols\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnumeric_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2132\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2133\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2134\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2135\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2175\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1267\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1269\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['series_id' 'device' 'idec'] not in index\""
     ]
    }
   ],
   "source": [
    "cat_vectorizer = create_cat_vectorizer(prepared)\n",
    "print(cat_vectorize(data.head(5), cat_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ids = prepared[\"track_id\"]\n",
    "\n",
    "vocab_size = track_ids.nunique()\n",
    "\n",
    "le = label_encoder(track_ids.values)\n",
    "\n",
    "print(le.transform(track_ids.values[0:5]))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[858 690 804]\n"
     ]
    }
   ],
   "source": [
    "def create_x_video_vectors(x, vocab_size):\n",
    "    x = x[\"track_id\"].values\n",
    "    x = le.transform(x)\n",
    "    x = x.astype(np.int32)\n",
    "#     x = np.expand_dims(x, axis=0).astype(np.int32)\n",
    "#     x = keras.utils.to_categorical(x, vocab_size)\n",
    "    return x\n",
    "\n",
    "    #     return np.repeat(np.expand_dims(x[\"track_id\"].values, axis=0), len(x), axis = 0).reshape(len(x), len(x))\n",
    "\n",
    "def create_x_num_cut_vectors(x):\n",
    "    vec_x_cat = cat_vectorizer.transform(x, cat_vectorizer)\n",
    "    print(vec_x_cat)\n",
    "    x_num = data[x].as_matrix()\n",
    "    print(x_num)\n",
    "    return np.hstack(x_num, vec_x_cat)\n",
    "\n",
    "def create_x(x, vocab_size):\n",
    "    return [create_x_video_vectors(x, vocab_size).astype(np.int32), create_x_num_cut_vectors(x)]\n",
    "    \n",
    "print(create_x(prepared.head(3), vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# one_hot = one_hot_encoder(prepared, \"track_id\", vocab_size)\n",
    "\n",
    "def create_y(y, vocab_size):\n",
    "    y = y[\"track_id\"].values\n",
    "    y = le.transform(y)\n",
    "    if (len(y) == 0):\n",
    "        return np.zeros(vocab_size)\n",
    "#     y = one_hot.transform(y[\"track_id\"][y[\"track_id\"].notnull()].values, axis = 1).toarray()\n",
    "#     y = np.expand_dims(y, axis=0).astype(np.int32)\n",
    "    return np.max(keras.utils.to_categorical(y, vocab_size), axis = 0)\n",
    "\n",
    "print(create_y(prepared.head(3), vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps(data, batch_size = 20):\n",
    "    return data[\"ip\"].nunique() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)\n",
      "(20, 955)\n",
      "[[144 146 149 150]\n",
      " [752 753 766 781]\n",
      " [348 348 726 825]\n",
      " [869 869 513 513]\n",
      " [888 897 832 810]\n",
      " [886 913 937 933]\n",
      " [781 844 781 781]\n",
      " [783 741 751 348]\n",
      " [879 880 913 933]\n",
      " [743 766 781 944]\n",
      " [159 160 160 161]\n",
      " [369 370 372 243]\n",
      " [764 944 887 944]\n",
      " [860 860 751 764]\n",
      " [913 933 937 952]\n",
      " [708 703 702 698]\n",
      " [860 880 860 906]\n",
      " [691 693 697 697]\n",
      " [348 348 348 348]\n",
      " [860 879 906 913]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def train_generator(seq_by_user, x_len = 4, batch_size = 20):\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    seq_len = len(seq_by_user)\n",
    "    \n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    iterator = iter(seq_by_user)\n",
    "    \n",
    "    while(True):\n",
    "        ip, group = next(iterator)\n",
    "        \n",
    "        group = group.sort_values(\"timestamp\")\n",
    "        x = create_x(group[0:x_len], vocab_size)\n",
    "        y = create_y(group[x_len:min(x_len + 4, len(group))], vocab_size)\n",
    "        \n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "        \n",
    "        step = step + 1\n",
    "        \n",
    "        if (step % batch_size == 0 or step >= seq_len):\n",
    "            batch = (np.array(x_list), np.array(y_list))\n",
    "            x_list = []\n",
    "            y_list = []\n",
    "            yield (batch)\n",
    "            \n",
    "        if (step >= seq_len):\n",
    "            iterator = iter(seq_by_user)\n",
    "            step = 0\n",
    "        \n",
    "generation = next(train_generator(extract_sequences_by_user(prepared)))\n",
    "print(generation[0].shape)\n",
    "print(generation[1].shape)\n",
    "print(generation[0])\n",
    "print(generation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_seq = extract_sequences_by_user(prepared[:100])\n",
    "# test_gen = train_generator(test_seq, 3)\n",
    "# for i in steps(test_seq, 3) * 2:\n",
    "#     print(next(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_train_flag(data):\n",
    "    split_val = prepared[\"ip\"].quantile(.8)\n",
    "    print(split_val)\n",
    "    prepared[\"train\"] = prepared[\"ip\"] < split_val\n",
    "    \n",
    "def train_test_split(data):\n",
    "    add_train_flag(data)\n",
    "    return (prepared[prepared[\"train\"] == True], prepared[prepared[\"train\"] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3822537001.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3923196\n",
      "980801\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(prepared)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21179.25\n",
      "6099.45\n"
     ]
    }
   ],
   "source": [
    "print(steps(train))\n",
    "print(steps(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 4, 100)            95500     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 4, 128)            88320     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 955)               489915    \n",
      "=================================================================\n",
      "Total params: 838,855\n",
      "Trainable params: 838,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "8472/8471 [==============================] - 729s 86ms/step - loss: 0.0232 - top_k_categorical_accuracy: 0.1858 - val_loss: 0.0228 - val_top_k_categorical_accuracy: 0.1916\n",
      "Epoch 2/3\n",
      " 428/8471 [>.............................] - ETA: 9:00 - loss: 0.0239 - top_k_categorical_accuracy: 0.1850"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-389031ff3485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_sequences_by_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_sequences_by_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2212\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# vocab_size = 248868\n",
    "# print(vocab_size)\n",
    "\n",
    "emb_input = keras.layers.Input(shape=(4,))\n",
    "\n",
    "num_cut_input = keras.layers.Input(shape=(500,))\n",
    "\n",
    "embedding = keras.layers.Embedding(vocab_size, 100, input_length=4)(emb_input)\n",
    "\n",
    "concat = keras.layers.Concatenate()(num_cut_input, embedding)\n",
    "\n",
    "# avg = keras.layers.Flatten()(keras.layers.AveragePooling1D(pool_size=1)(embedding))\n",
    "\n",
    "#input_num_cat = keras.layers.Input(shape = num_cat_shape)\n",
    "#concat = keras.layers.Concat(embedding, input_num_cat)\n",
    "gru_1 = keras.layers.CuDNNGRU(128, return_sequences=True)(concat)\n",
    "gru_2 = keras.layers.CuDNNGRU(128)(gru_1)\n",
    "\n",
    "dense_1 = keras.layers.Dense(512, activation = \"relu\")(gru_2)\n",
    "# dense_2 = keras.layers.Dense(512, activation = \"relu\")(dense_1)\n",
    "drop = keras.layers.Dropout(0.5)(dense_1)\n",
    "dense_4 = keras.layers.Dense(vocab_size, activation = \"tanh\")(drop)\n",
    "\n",
    "model = keras.models.Model(inputs=emb_input, outputs=dense_4)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['top_k_categorical_accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit_generator(train_generator(extract_sequences_by_user(train), batch_size=50), steps_per_epoch=steps(train, 50), validation_data = train_generator(extract_sequences_by_user(test)), validation_steps=steps(test), epochs=3, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 955)\n",
      "(20, 955)\n"
     ]
    }
   ],
   "source": [
    "val_batch = next(train_generator(extract_sequences_by_user(test)))\n",
    "y_true = val_batch[1]\n",
    "y_predicted = model.predict(val_batch[0])\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 139]\n",
      " [  0 887]\n",
      " [  0 944]\n",
      " [  0 950]\n",
      " [  1 332]\n",
      " [  1 628]\n",
      " [  1 647]\n",
      " [  1 887]\n",
      " [  2 173]\n",
      " [  2 177]\n",
      " [  2 196]\n",
      " [  2 839]\n",
      " [  3 539]\n",
      " [  3 887]\n",
      " [  4 170]\n",
      " [  4 391]\n",
      " [  4 680]\n",
      " [  4 753]\n",
      " [  5 154]\n",
      " [  5 702]\n",
      " [  5 929]\n",
      " [  5 933]\n",
      " [  6 139]\n",
      " [  6 721]\n",
      " [  6 891]\n",
      " [  6 944]\n",
      " [  7 901]\n",
      " [  7 906]\n",
      " [  7 933]\n",
      " [  7 944]\n",
      " [  8 534]\n",
      " [  8 676]\n",
      " [  8 887]\n",
      " [  9 742]\n",
      " [  9 743]\n",
      " [  9 842]\n",
      " [  9 887]\n",
      " [ 10  48]\n",
      " [ 10 515]\n",
      " [ 10 671]\n",
      " [ 10 944]\n",
      " [ 11 742]\n",
      " [ 11 941]\n",
      " [ 11 944]\n",
      " [ 12 894]\n",
      " [ 12 933]\n",
      " [ 12 944]\n",
      " [ 12 950]\n",
      " [ 13 887]\n",
      " [ 13 906]\n",
      " [ 14 327]\n",
      " [ 14 760]\n",
      " [ 14 887]\n",
      " [ 15 887]\n",
      " [ 15 908]\n",
      " [ 16 702]\n",
      " [ 16 887]\n",
      " [ 17 552]\n",
      " [ 17 887]\n",
      " [ 17 894]\n",
      " [ 17 944]\n",
      " [ 18 173]\n",
      " [ 18 944]\n",
      " [ 19 596]\n",
      " [ 19 764]\n",
      " [ 19 887]\n",
      " [ 19 894]]\n",
      "[[  0 130]\n",
      " [  0 150]\n",
      " [  0 348]\n",
      " ...\n",
      " [ 16 949]\n",
      " [ 16 950]\n",
      " [ 16 952]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = np.rint(y_predicted)\n",
    "\n",
    "true_y_values = np.transpose(np.nonzero(y_true))[:, 1:]\n",
    "pred_y_values = np.transpose(np.nonzero(y_predicted))[:, :1]\n",
    "\n",
    "true_y_track_values = le.inverse_transform(true_y_values)\n",
    "pred_y_track_values = le.inverse_transform(pred_y_values)\n",
    "\n",
    "# y_true = np.array(np.nonzero(y_true)).flatten()\n",
    "# y_predicted = np.array(np.nonzero(y_predicted)).flatten()\n",
    "\n",
    "# print(y_true.shape)\n",
    "# print(y_predicted.shape)\n",
    "\n",
    "# def inverse(x):\n",
    "#     if x > 0 : \n",
    "#         return le.inverse_transform(x) \n",
    "#     else :\n",
    "#         return 0\n",
    "        \n",
    "# inverse = np.vectorize(inverse)\n",
    "# y_true = inverse(y_true)\n",
    "# y_predicted = inverse(y_predicted) if len (y_predicted) > 0 else y_predicted\n",
    "\n",
    "# print(y_true)\n",
    "# print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_video(track_id, video_catalog):\n",
    "    video_catalog['season'] = pd.to_numeric(video_catalog['season'], errors='coerce', downcast = 'integer')\n",
    "    video_catalog['episode'] = pd.to_numeric(video_catalog['episode'], errors='coerce', downcast = 'integer')\n",
    "\n",
    "    curent_video = video_catalog.loc[video_catalog['track_id'] == track_id]\n",
    "\n",
    "    if curent_video.size == 0:\n",
    "        return False\n",
    "\n",
    "    curent_video_index = curent_video.index[0]\n",
    "    \n",
    "    curent_title = curent_video['title'][[curent_video_index][0]]\n",
    "    curent_season = curent_video['season'][[curent_video_index][0]]\n",
    "    curent_episod = curent_video['episode'][[curent_video_index][0]]\n",
    "    \n",
    "    this_show_season = video_catalog.loc[(video_catalog['season'] == curent_season) & (video_catalog.title == curent_title)]\n",
    "    next_episods = this_show_season.loc[this_show_season['episode'] > curent_episod]\n",
    "\n",
    "    if next_episods.episode.size != 0:\n",
    "        next_min_episode = next_episods.episode.min()\n",
    "        next_min_episode_index = next_episods.loc[next_episods.episode == next_min_episode].index[0]\n",
    "        next = video_catalog.ix[next_min_episode_index]\n",
    "    else:\n",
    "        next_seasons = video_catalog.loc[(video_catalog['season'] > curent_season) & (video_catalog.title == curent_title)]\n",
    "        if next_seasons.season.size != 0:\n",
    "            next_min_season_min_episode = next_seasons.episode.min()\n",
    "            next = next_seasons.loc[next_seasons['episode'] == next_min_season_min_episode]\n",
    "        else:\n",
    "            next = False\n",
    "\n",
    "    return next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_popular_video(video_history):\n",
    "    return video_history.groupby('track_id').apply(lambda x: x.count()).sort_values(by=['ip'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_video_id_by_track_id(id): \n",
    "    video_id = catalog.loc[catalog['track_id'] == id]['video_id']\n",
    "    return video_id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(data):\n",
    "    video_array = []\n",
    "    \n",
    "    for d in data:\n",
    "        d = find_video_id_by_track_id(d)\n",
    "        video_array.append(d)\n",
    "        \n",
    "    return video_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_videos = get_videos(true_y_track_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
